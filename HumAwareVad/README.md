# HumAware-VAD: Humming-Aware Voice Activity Detection

## Demo


https://github.com/user-attachments/assets/ea06a06f-d9e8-4203-a982-56326d160c9e


## üìå Overview
**HumAware-VAD** is a fine-tuned version of the **[Silero-VAD](https://github.com/snakers4/silero-vad/tree/master)** model, trained to distinguish **humming from actual speech**. Standard Voice Activity Detection (VAD) models, including Silero-VAD, often misclassify humming as speech, leading to inaccurate speech segmentation. HumAware-VAD improves upon this by leveraging a custom dataset (**[HumSpeechBlend](https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend)**) to enhance speech detection accuracy in the presence of humming.

## üéØ Purpose
The primary goal of **HumAware-VAD** is to:
- Reduce **false positives** where humming is mistakenly detected as speech.
- Enhance **speech segmentation accuracy** in real-world applications.
- Improve VAD performance for tasks involving **music, background noise, and vocal sounds**.

## üóÇÔ∏è Model Details
- **Base Model**: [Silero-VAD](https://github.com/snakers4/silero-vad/tree/master)
- **Fine-tuning Dataset**: [HumSpeechBlend](https://huggingface.co/datasets/CuriousMonkey7/HumSpeechBlend)
- **Format**: JIT (TorchScript)
- **Framework**: PyTorch
- **Inference Speed**: Real-time

## üöÄ Using HumAware-VAD with FastRTC
You can integrate **HumAware-VAD** with **FastRTC** for real-time voice activity detection in streaming applications.

### Installation
```sh
pip install humaware-vad
```

### Clone the this Repository  
```sh
git clone https://github.com/CuriousMonkey7/HumAwareVad.git
cd HumAwareVad
```
Run the script:
```sh
python app.py
```

## ‚ö†Ô∏è Limitations
- The model may **miss speech detection** if the user speaks too softly.
- Works best for detecting **"mhm" humming sounds**.
- May also work for sounds like **"la la la"** or **"da da da"**, but with **varying accuracy**.




<!-- 
## üì• Download & Usage
### üîπ Install Dependencies
```bash
pip install humaware-vad
```

### üîπ Load the Model
```python

### Clone this repo
```sh
git clone https://github.com/CuriousMonkey7/HumAwareVad.git
cd HumAwareVad
```
```

### üîπ Run Inference
```python
import torchaudio

waveform, sample_rate = torchaudio.load("data/0000.wav")
out = vad_model(waveform)
print("VAD Output:", out)
``` -->
<!-- 
## üèÜ Performance
Compared to the base Silero-VAD model, **HumAware-VAD** demonstrates:
‚úÖ **Lower false positives for humming**
‚úÖ **Better segmentation of speech in mixed audio**
‚úÖ **Maintained real-time inference capabilities**

## üìä Applications
- **Automatic Speech Recognition (ASR) Preprocessing**
- **Noise-Robust VAD Systems**
- **Speech Enhancement & Separation**
- **Call Center & Voice Communication Filtering** -->

## üìÑ Citation
If you use this model, please cite it accordingly.

```
@model{HumAwareVAD2025,
  author = {Sourabh Saini},
  title = {HumAware-VAD: Humming-Aware Voice Activity Detection},
  year = {2025},
  publisher = {Hugging Face},
  url = {https://huggingface.co/CuriousMonkey7/HumAware-VAD}
}
```
